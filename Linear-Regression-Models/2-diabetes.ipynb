{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Diabetes\n",
    "\n",
    "In this part of the assignment, you will build a predictive model for diabetes disease progression in the next year based on current observed features of disease symptoms. \n",
    "\n",
    "**Learning objectives.** You will:\n",
    "1. Train and test a linear model using ordinary least squares regression.\n",
    "2. Use numerical Python (NumPy) and the standard `sklearn` API in Python  \n",
    "3. Train and test a polynomial model, comparing to the linear model and demonstrating overfitting\n",
    "4. Apply regularization, specifically LASSO, to build a sparse linear model\n",
    "\n",
    "The following code will download and preview three examples of the data. The ten features are as follows (in order):\n",
    "\n",
    "- age age in years\n",
    "- sex\n",
    "- bmi body mass index\n",
    "- bp average blood pressure\n",
    "- s1 tc, total serum cholesterol\n",
    "- s2 ldl, low-density lipoproteins\n",
    "- s3 hdl, high-density lipoproteins\n",
    "- s4 tch, total cholesterol / HDL\n",
    "- s5 ltg, log of serum triglycerides level\n",
    "- s6 glu, blood sugar level\n",
    "\n",
    "The target value is a quantiative measure of disease progression after 1 year, where larger numbers are worse.\n",
    "\n",
    "The code stores the feature matrix `X` as a two-dimensional NumPy array where each row corresponds to a data point and each column is a feature. The target value is stored as a one-dimensional NumPy array `y` where the index `i` element of `y` correpsonds to the row `i` data point of `X`.\n",
    "\n",
    "Your overall goal in this part is to build and evaluate a linear model to predict the target variable `y` as a function of the ten features in `X`, and to identify which features are more significant for predicting `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n",
      "[[ 59.       2.      32.1    101.     157.      93.2     38.       4.\n",
      "    4.8598  87.    ]\n",
      " [ 48.       1.      21.6     87.     183.     103.2     70.       3.\n",
      "    3.8918  69.    ]\n",
      " [ 72.       2.      30.5     93.     156.      93.6     41.       4.\n",
      "    4.6728  85.    ]]\n",
      "[151.  75. 141.]\n"
     ]
    }
   ],
   "source": [
    "# Run but DO NOT MODIFY this code\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes = load_diabetes(scaled = False)\n",
    "print(diabetes.feature_names)\n",
    "\n",
    "# Get the feature data and target variable\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "\n",
    "# Preview the first 3 data points\n",
    "print(X[:3])\n",
    "print(y[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "Use `sklearn` to randomly split the input data into a [train and test partition](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html), with 30% of the data reserved for testing. Use a random seed of `2025` for reproducibility of the results.\n",
    "\n",
    "Print the number of data points in the resulting train and test partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points in the resulting train partition is 309\n",
      "Number of data points in the resulting test partition is 133\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Write task 1 code here\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 2025)\n",
    "print(\"Number of data points in the resulting train partition is\", X_train.shape[0])\n",
    "print(\"Number of data points in the resulting test partition is\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Build a baseline prediction by computing the [average](https://numpy.org/doc/stable/reference/generated/numpy.mean.html) target value of the training data and predicting this for average for every test data point.\n",
    "\n",
    "For example, if the training data target values were `[2, 2, 5]` then you would compute the average as `3`. If there there were only two test data points, then your predictions would be simply `[3, 3]`.\n",
    "\n",
    "Evaluate the [root mean squared error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.root_mean_squared_error.html#sklearn.metrics.root_mean_squared_error) between the baseline and the test data.\n",
    "\n",
    "This RMSE will serve as a benchmark - any useful model should achieve a lower error than this simple baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE between baseline predictions and y_test is 75.8165287907097\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "# Write task 2 code here\n",
    "y_train_mean = np.mean(y_train)\n",
    "y_baseline_prediction = np.full_like(y_test, y_train_mean)\n",
    "RMSE_baseline = root_mean_squared_error(y_test, y_baseline_prediction)\n",
    "print(\"The RMSE between baseline predictions and y_test is\", RMSE_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "Use [`sklearn`](https://scikit-learn.org/stable/) to fit a linear predictive model on the training data using [ordinary least squares regression](https://scikit-learn.org/stable/modules/linear_model.html#ordinary-least-squares). \n",
    "\n",
    "Evaluate the [root mean squared error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.root_mean_squared_error.html#sklearn.metrics.root_mean_squared_error) of the model on **both** the training data **and** the test data (that is, the training error and the generalization error). Report both results.\n",
    "\n",
    "Note that the model predictions on the test data may not be perfect, but they should improve meaningfully over the simple baseline from Task 2 or something is wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE of the model on the training data is 52.97771955290354\n",
      "The RMSE of the model on the test data is 55.14187488833094\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Write task 3 code here\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "RMSE_train = root_mean_squared_error(y_train, y_train_pred)\n",
    "RMSE_test = root_mean_squared_error(y_test, y_test_pred)\n",
    "print(\"The RMSE of the model on the training data is\", RMSE_train)\n",
    "print(\"The RMSE of the model on the test data is\", RMSE_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "\n",
    "To understand which input features are most important for predicting diabetes progression, we need a model that can automatically select relevant features. The ordinary least squares model from Task 3 uses all features, making it harder to identify which ones truly matter.\n",
    "\n",
    "Build a new linear model using [Lasso regression](https://scikit-learn.org/stable/modules/linear_model.html#lasso) that meets two criteria:\n",
    "  - Performance: At most 10% greater error than the linear model with all the features in task 3. \n",
    "  - Sparsity: At least three model coefficients set to 0 (meaning the model does not use these features to make predictions). You can treat any coefficient less than 0.0001 as effectively 0 for this task.\n",
    "\n",
    "You may need to try multiple vaues of the `alpha` *hyperparameter* to find a satisfy both constraints. For example, you can try [0.1, 1, 5, 10, ...]. The final LASSO model is only required to satisfy the above two criteria. Nevertheless, you should only evaluate error on the test dataset **once** after searching for such a value of `alpha`. Use [cross validation](https://scikit-learn.org/stable/modules/cross_validation.html) on the training data or split the training data into train and validation sets.\n",
    "\n",
    "For your final Lasso model with the chosen `alpha` fit on all of the training data, report the [root mean squared error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.root_mean_squared_error.html#sklearn.metrics.root_mean_squared_error) of the model predictions on the test data. Report the three or more features for which the model coefficients were set to 0 (see feature names/interpretations above). Also please explain why you selected this `alpha`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chosen alpha for the final Lasso model is 16.0\n",
      "The test RMSE for the Lasso model is 56.36195251114452\n",
      "Does the Lasso model meet the performance requirement?: True\n",
      "Does the Lasso model meet the sparsity requirement?: True\n",
      "Features that have zero coefficients are ['age', 'sex', 's4', 's5']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Write task 4 code here\n",
    "X_train_sub, X_validation, y_train_sub, y_validation = train_test_split(X_train, y_train, test_size = 0.3, random_state = 2025)\n",
    "alphas = np.r_[1e-3, 1e-2, 1e-1, np.arange(1, 101)]\n",
    "results = []\n",
    "for curr_alpha in alphas:\n",
    "    temp_lasso_model = Lasso(alpha = curr_alpha)\n",
    "    temp_lasso_model.fit(X_train_sub, y_train_sub)\n",
    "    y_temp_prediction = temp_lasso_model.predict(X_validation)\n",
    "    RMSE_value = root_mean_squared_error(y_validation, y_temp_prediction)\n",
    "    num_coef_zeros = np.sum(np.abs(temp_lasso_model.coef_) < 1e-4)\n",
    "    results.append((curr_alpha, RMSE_value, num_coef_zeros))\n",
    "good_candidates = sorted([result for result in results if result[2] >= 3], key = lambda r: r[1])\n",
    "final_alpha = None\n",
    "final_lasso_model = None\n",
    "final_zero_count = None\n",
    "final_zero_features = None\n",
    "for candidate_alpha, candidate_RMSE, candidate_coef_zeros in good_candidates:\n",
    "    current_final_lasso_model = Lasso(alpha = candidate_alpha)\n",
    "    current_final_lasso_model.fit(X_train, y_train)\n",
    "    zero_count = int((np.abs(current_final_lasso_model.coef_) < 1e-4).sum())\n",
    "    if zero_count >= 3:\n",
    "        final_alpha = candidate_alpha\n",
    "        final_lasso_model = current_final_lasso_model\n",
    "        final_zero_count = zero_count\n",
    "        final_zero_features = [name for name, zero in zip(diabetes.feature_names, np.abs(current_final_lasso_model.coef_) < 1e-4) if zero]\n",
    "        break\n",
    "y_test_lasso_pred = final_lasso_model.predict(X_test)\n",
    "RMSE_test_lasso_model = root_mean_squared_error(y_test, y_test_lasso_pred)\n",
    "print(\"The chosen alpha for the final Lasso model is\", final_alpha)\n",
    "print(\"The test RMSE for the Lasso model is\", RMSE_test_lasso_model)\n",
    "print(\"Does the Lasso model meet the performance requirement?:\", RMSE_test_lasso_model <= (RMSE_test * 1.10))\n",
    "print(\"Does the Lasso model meet the sparsity requirement?:\", final_zero_count >= 3)\n",
    "print(\"Features that have zero coefficients are\", final_zero_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My final alpha I ultimately selected was 16.0 as the final lasso model manages to pass the performance and sparsity requirements. To select this alpha value, I first split the training data into training and validation sets. For each alpha I trained on the new training data, I computed the validation RMSE, counted how many coefficients were zero, and added the tuple into the result list. I then sorted the result list based on validation RMSE and if the number of features that have a coefficent of zero is at least 3 which makes the alpha a good candidate. I then ran another for loop where I refit each alpha candidate on the full training set and break once a candidate model has at least three features with coefficients of zero. Once I break the loop, I eveluate the model on the test set. \n",
    "\n",
    "Initially, I only used one for loop where I just used the result of the validation split to see which alpha meets the criteria. My first alpha I selected was 3.0 since it has a good validation RMSE and has 3 features that has a coefficent of zero. But when I refitted the model with alpha being 3.0 on the entire training set and looked at the coefficents, I saw that only 2 coefficents were below the 0.0001 threshold. I find that with Lasso, small changes in the training data like going from sub training data to full training data does alter the coefficents to the point that the final model no longer satisfies the sparsity requirement. This is why I decided to create another for loop over the sorted candidates to see if the model with the full training data and the alpha value are able to pass the requirements.\n",
    "\n",
    "At the end, the alpha I chosen is 16.0 as it was the smallest error model that can still pass the sparsity requirement with at least three features having coefficients of zero after refitting on the full training set. This model also passes the performance requirement as the test RMSE is at most 10% greater error than the linear model with all the features in task 3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
